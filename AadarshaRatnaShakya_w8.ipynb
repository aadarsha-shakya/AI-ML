{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7DGbuYtB1JI",
        "outputId": "4448a3ae-776b-4f75-9ef5-2e0a0f15388f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/trum_tweet_sentiment_analysis.csv\", encoding=\"ISO-8859-1\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zDTaFfurX07a",
        "outputId": "31044b2c-5f08-451f-e298-b00feee4c604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  Sentiment\n",
              "0  RT @JohnLeguizamo: #trump not draining swamp b...          0\n",
              "1  ICYMI: Hackers Rig FM Radio Stations To Play A...          0\n",
              "2  Trump protests: LGBTQ rally in New York https:...          1\n",
              "3  \"Hi I'm Piers Morgan. David Beckham is awful b...          0\n",
              "4  RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22253dd4-8af3-4789-9474-35b08125e4c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @JohnLeguizamo: #trump not draining swamp b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICYMI: Hackers Rig FM Radio Stations To Play A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump protests: LGBTQ rally in New York https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Hi I'm Piers Morgan. David Beckham is awful b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22253dd4-8af3-4789-9474-35b08125e4c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22253dd4-8af3-4789-9474-35b08125e4c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22253dd4-8af3-4789-9474-35b08125e4c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08590585-550f-4ede-b49d-72ac3edcfe3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08590585-550f-4ede-b49d-72ac3edcfe3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08590585-550f-4ede-b49d-72ac3edcfe3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaning = data[\"text\"].dropna()"
      ],
      "metadata": {
        "id": "sdPjbAYzZspp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cleaning[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HRQSKAiaZxNG",
        "outputId": "dcec6e02-575e-4ec3-fa63-de4ce562ee30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @JohnLeguizamo: #trump not draining swamp but our taxpayer dollars on his trips to advertise his properties! @realDonaldTrumpÂ\\x85 https://t.co/gFBvUkMX9z'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Sentiment']  # Target variable (labels)"
      ],
      "metadata": {
        "id": "HpdqvSeM2fZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_urls(text):\n",
        "  \"\"\"\n",
        "  This function will try to remove URL present in out dataset and replace it with space using regex library.\n",
        "  Input Args:\n",
        "  text: strings of text that may contain URLs.\n",
        "  Output Args:\n",
        "  text: URLs replaces with text\n",
        "  \"\"\"\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "BzJ_Rkf4ajvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" Click on this link to open facebook https://www./\"\n",
        "text_url = remove_urls(text)"
      ],
      "metadata": {
        "id": "fhusNe9lbZAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_bHU70-Zbaxm",
        "outputId": "74676145-417b-4438-b9b8-ab2b4ef10016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Click on this link to open facebook '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(string):\n",
        "  \"\"\"\n",
        "  This function will replace the emoji in string with whitespace\n",
        "  \"\"\"\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r' ', string)"
      ],
      "metadata": {
        "id": "QghKw-UYbd3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_string = \"Hello @siman 👋🏾, still on up for the movie???  #MovieNight #friday #🍱\"\n",
        "no_emoji = remove_emoji(test_string)\n",
        "print(no_emoji)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rFD5SjmbfQu",
        "outputId": "b7439feb-d81b-47ed-ff1b-af61a0b77df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello @siman  , still on up for the movie???  #MovieNight #friday # \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeunwanted_characters(document):\n",
        "  \"\"\"\n",
        "  This function will remove all the unwanted characters from the input dataset.\n",
        "  Input Args:\n",
        "  documet: A text data to be cleaned.\n",
        "  Return:\n",
        "  A cleaned document.\n",
        "  \"\"\"\n",
        "  # remove user mentions\n",
        "  document = re.sub(\"@[A-Za-z0-9_]+\",\" \", document)\n",
        "  # remove hashtags\n",
        "  document = re.sub(\"#[A-Za-z0-9_]+\",\"\", document)\n",
        "  # remove punctuation\n",
        "  document = re.sub(\"[^0-9A-Za-z ]\", \"\" , document)\n",
        "  #remove emojis\n",
        "  document = remove_emoji(document)\n",
        "  # remove double spaces\n",
        "  document = document.replace('  ',\"\")\n",
        "  return document.strip()"
      ],
      "metadata": {
        "id": "WsRfhZN3biAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "cleaned_string = removeunwanted_characters(test_string)\n",
        "cleaned_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vp09fTWqbjec",
        "outputId": "c81ec19d-a17a-42b1-ebb7-83fe1a124fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hellostill on up for the movie'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcG7vWe9bm7v",
        "outputId": "d7392f0a-e146-493b-a22e-c0948d9fc95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "# Test case:\n",
        "IN = \"He did not try to navigate after the first bold flight, for the reaction had taken something out of his soul.\"\n",
        "OUT = word_tokenize(IN)\n",
        "OUT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtS7qjFRbpjW",
        "outputId": "3ffbc039-7afd-4842-ae58-c791682e506e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He',\n",
              " 'did',\n",
              " 'not',\n",
              " 'try',\n",
              " 'to',\n",
              " 'navigate',\n",
              " 'after',\n",
              " 'the',\n",
              " 'first',\n",
              " 'bold',\n",
              " 'flight',\n",
              " ',',\n",
              " 'for',\n",
              " 'the',\n",
              " 'reaction',\n",
              " 'had',\n",
              " 'taken',\n",
              " 'something',\n",
              " 'out',\n",
              " 'of',\n",
              " 'his',\n",
              " 'soul',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "def remove_punct(text):\n",
        "  \"\"\"\n",
        "  This function removes the punctutations present in our text data.\n",
        "  Input Args:\n",
        "  text: text data.\n",
        "  Returns:\n",
        "  text: cleaned text.\n",
        "  \"\"\"\n",
        "  tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "  lst=tokenizer.tokenize(' '.join(text))\n",
        "  return lst\n"
      ],
      "metadata": {
        "id": "HPDMJtQQbtoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "text_punctutation = \"He did not try to navigate: after the!!!! first bold flight, for,,,,, the reaction!!!!had taken??????? something out of his soul.\"\n",
        "text_punc_token = word_tokenize(text_punctutation)\n",
        "print(text_punctutation)\n",
        "print(\"+++++++++++++++++_____________________+++++++++++++++++++++\")\n",
        "print(text_punc_token)\n",
        "print(\"_____________________+++++++++++++++++++++++++++__________________\")\n",
        "text_clean = remove_punct(text_punc_token)\n",
        "print(text_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67zBmUtbvKh",
        "outputId": "7faea668-4b4c-4f86-d927-87340443206c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He did not try to navigate: after the!!!! first bold flight, for,,,,, the reaction!!!!had taken??????? something out of his soul.\n",
            "+++++++++++++++++_____________________+++++++++++++++++++++\n",
            "['He', 'did', 'not', 'try', 'to', 'navigate', ':', 'after', 'the', '!', '!', '!', '!', 'first', 'bold', 'flight', ',', 'for', ',', ',', ',', ',', ',', 'the', 'reaction', '!', '!', '!', '!', 'had', 'taken', '?', '?', '?', '?', '?', '?', '?', 'something', 'out', 'of', 'his', 'soul', '.']\n",
            "_____________________+++++++++++++++++++++++++++__________________\n",
            "['He', 'did', 'not', 'try', 'to', 'navigate', 'after', 'the', 'first', 'bold', 'flight', 'for', 'the', 'reaction', 'had', 'taken', 'something', 'out', 'of', 'his', 'soul']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stopwords = ['@', 'RT']\n",
        "stop_words.update(custom_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOf3oybeb0uq",
        "outputId": "99955b25-9ec5-4121-a979-ca14ca0c0f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stopwords(text_tokens):\n",
        "  \"\"\"\n",
        "  This function removes all the stopwords present in out text tokens.\n",
        "  Input Args:\n",
        "  text_tokens: tokenize input of our datasets.\n",
        "  Returns:\n",
        "  result_tokens: list of token without stopword.\n",
        "  \"\"\"\n",
        "\n",
        "  result_tokens = []\n",
        "  for token in text_tokens:\n",
        "    if token not in stop_words:\n",
        "       result_tokens.append(token)\n",
        "  return result_tokens"
      ],
      "metadata": {
        "id": "mO72AYf3b15t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs = ['He', 'did', 'not', 'try', 'to', 'navigate', 'after', 'the', 'first', 'bold', 'flight', ',', 'for', 'the', 'reaction', 'had', 'taken', 'something', 'out', 'of', 'his', 'soul', '.']\n",
        "print(test_inputs)\n",
        "tokens_without_stopwords = remove_stopwords(test_inputs)\n",
        "print(tokens_without_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojsgnURTb3I2",
        "outputId": "0fcd720e-0f7d-42f4-f2bf-d41816f600c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'did', 'not', 'try', 'to', 'navigate', 'after', 'the', 'first', 'bold', 'flight', ',', 'for', 'the', 'reaction', 'had', 'taken', 'something', 'out', 'of', 'his', 'soul', '.']\n",
            "['He', 'try', 'navigate', 'first', 'bold', 'flight', ',', 'reaction', 'taken', 'something', 'soul', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize,pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatization(token_text):\n",
        "  \"\"\"\n",
        "  This function performs the lemmatization operations as explained above.\n",
        "  Input Args:\n",
        "  token_text: list of tokens.\n",
        "  Returns:\n",
        "  lemmatized_tokens: list of lemmatized tokens.\n",
        "  \"\"\"\n",
        "  lemma_tokens = []\n",
        "  wordnet = WordNetLemmatizer()\n",
        "  lemmatized_tokens = [wordnet.lemmatize(token, pos = 'v') for token in token_text]\n",
        "\n",
        "  return lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neCZgQSVb70t",
        "outputId": "4f41e0fc-3331-4a6f-dd19-1c09a217c14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatization(\"Should we go walking or swimming\".split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMkCIMY2b9bI",
        "outputId": "0b34bbdd-68ea-4248-f36c-9abe3c049a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Should', 'we', 'go', 'walk', 'or', 'swim']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_order(text):\n",
        "  \"\"\"\n",
        "  This function converts all the text in input text to lower order.\n",
        "  Input Args:\n",
        "  token_text : input text.\n",
        "  Returns:\n",
        "  small_order_text : text converted to small/lower order.\n",
        "  \"\"\"\n",
        "  small_order_text = text.lower()\n",
        "  return small_order_text\n",
        "\n",
        "# Test:\n",
        "sample_text = \"This Is some Normalized TEXT\"\n",
        "sample_small = lower_order(sample_text)\n",
        "print(sample_small)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9bxgnLScAnQ",
        "outputId": "ca439b96-da47-4f2b-de50-2024d4014178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is some normalized text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function for Text Cleaning:\n",
        "\n",
        "Implement a Helper Function as per Text Preprocessing Notebook and Complete the following pipeline."
      ],
      "metadata": {
        "id": "SxV-QBHp-B6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Text Cleaning Pipeline"
      ],
      "metadata": {
        "id": "B-llg-TI_Drw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning_pipeline(dataset, rule = \"lemmatize\"):\n",
        "  \"\"\"\n",
        "  This...\n",
        "  \"\"\"\n",
        "  # Convert the input to small/lower order.\n",
        "  da =str(dataset)\n",
        "  data= da.lower()\n",
        "  # Remove URLs\n",
        "  data=remove_urls(da)\n",
        "  # Remove emojis\n",
        "  data =remove_emoji(data)\n",
        "  # Remove all other unwanted characters.\n",
        "  data =removeunwanted_characters(data)\n",
        "  # Create tokens.\n",
        "  tokens = data.split()\n",
        "  # Remove stopwords:\n",
        "  tokens =remove_stopwords(tokens)\n",
        "\n",
        "  # Perform lemmatization:\n",
        "  if rule == \"lemmatize\":\n",
        "    tokens =lemmatization(tokens)\n",
        "  else:\n",
        "    print(\"Pick between lemmatize or stem\")\n",
        "\n",
        "\n",
        "  return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "KCT1T3-68tN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = data['text']  # Features (text data)\n",
        "y = data['Sentiment']  # Target variable (labels)\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "0rVTMyjgd4Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=2500)\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "YSrT60Hi3TJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzYhEDSzx0-y",
        "outputId": "677e3d46-c4dd-492e-8bb0-647cb623ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92    248563\n",
            "           1       0.86      0.78      0.81    121462\n",
            "\n",
            "    accuracy                           0.88    370025\n",
            "   macro avg       0.88      0.86      0.86    370025\n",
            "weighted avg       0.88      0.88      0.88    370025\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification using Machine Learning Models\n"
      ],
      "metadata": {
        "id": "hzMm4-1KCNkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 Instructions: Trump Tweet Sentiment Classification\n",
        "\n",
        "1. **Load the Dataset**  \n",
        "   Load the dataset named `\"trump_tweet_sentiment_analysis.csv\"` using `pandas`. Ensure the dataset contains at least two columns: `\"text\"` and `\"label\"`.\n",
        "\n",
        "2. **Text Cleaning and Tokenization**  \n",
        "   Apply a text preprocessing pipeline to the `\"text\"` column. This should include:\n",
        "   - Lowercasing the text  \n",
        "   - Removing URLs, mentions, punctuation, and special characters  \n",
        "   - Removing stopwords  \n",
        "   - Tokenization (optional: stemming or lemmatization)\n",
        "   - \"Complete the above function\"\n",
        "\n",
        "3. **Train-Test Split**  \n",
        "   Split the cleaned and tokenized dataset into **training** and **testing** sets using `train_test_split` from `sklearn.model_selection`.\n",
        "\n",
        "4. **TF-IDF Vectorization**  \n",
        "   Import and use the `TfidfVectorizer` from `sklearn.feature_extraction.text` to transform the training and testing texts into numerical feature vectors.\n",
        "\n",
        "5. **Model Training and Evaluation**  \n",
        "   Import **Logistic Regression** (or any machine learning model of your choice) from `sklearn.linear_model`. Train it on the TF-IDF-embedded training data, then evaluate it using the test set.  \n",
        "   - Print the **classification report** using `classification_report` from `sklearn.metrics`.\n"
      ],
      "metadata": {
        "id": "oFltIxr9L2Wu"
      }
    }
  ]
}